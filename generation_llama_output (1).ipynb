{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "hjkQbcGTnTqo",
        "outputId": "b8cea2f1-ee86-4a25-8ed7-7638a8695996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformer_lens\n",
            "  Downloading transformer_lens-2.16.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (1.9.0)\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.0.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.8.1)\n",
            "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
            "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting numpy<2,>=1.24 (from transformer_lens)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.2.2)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (13.9.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.2.0)\n",
            "Requirement already satisfied: torch>=2.6 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.51 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.53.3)\n",
            "Collecting transformers-stream-generator<0.0.6,>=0.0.5 (from transformer_lens)\n",
            "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.14.1)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.21.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.33.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2025.3.0)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.2.11->transformer_lens)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens) (2.19.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6->transformer_lens) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6->transformer_lens) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.6->transformer_lens)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.6->transformer_lens)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.6->transformer_lens)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.6->transformer_lens)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.6->transformer_lens)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.6->transformer_lens)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.6->transformer_lens)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.6->transformer_lens)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.6->transformer_lens)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6->transformer_lens) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6->transformer_lens) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6->transformer_lens) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.6->transformer_lens)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6->transformer_lens) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6->transformer_lens) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51->transformer_lens) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51->transformer_lens) (0.21.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (2.11.7)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (2.33.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (3.12.14)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.23.0->transformer_lens) (1.1.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.13.5->transformer_lens) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->transformer_lens) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6->transformer_lens) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (1.20.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.2)\n",
            "Downloading transformer_lens-2.16.1-py3-none-any.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.0/192.0 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: transformers-stream-generator\n",
            "  Building wheel for transformers-stream-generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers-stream-generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12426 sha256=3cb45973fd0ce89da052d3165eb339e0a450e42c5e93fdcad18af84d222296e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/e8/f0/b3c58c12d1ffe60bcc8c7d121115f26b2c1878653edfca48db\n",
            "Successfully built transformers-stream-generator\n",
            "Installing collected packages: better-abc, wadler-lindig, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fancy-einsum, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxtyping, nvidia-cusolver-cu12, transformers-stream-generator, transformer_lens\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beartype-0.14.1 better-abc-0.0.3 fancy-einsum-0.0.3 jaxtyping-0.3.2 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformer_lens-2.16.1 transformers-stream-generator-0.0.5 wadler-lindig-0.1.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "77cec4b6a58c4982ad0cc8301235ed74"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install transformer_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKLZKbhTnqv8"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from transformer_lens import HookedTransformer\n",
        "from transformer_lens.utils import test_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM15WIT1oQYa"
      },
      "outputs": [],
      "source": [
        "import os, json\n",
        "from typing import Union, Optional, Dict, Any, List, Tuple\n",
        "from rich import print as rprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgmVzC7fgiO5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(os.getenv(\"HF_TOKEN\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoMt1Xrooc_Y",
        "outputId": "8eabe0c3-c632-40ce-cb81-182d7f3d1c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "db58dc77bafb48229929c12720ea717f",
            "7d7e5c786baa4d059a4cb9e734062484",
            "75377575d534485da83c4b09d3e4bfa5",
            "a054f4348c27427796fec99e5932b9de",
            "81e7a85263e940168bfd349a4ec68954",
            "a8c15255b4434e699313d94a6dbf8ad1",
            "cc19cf3c6a694706835769d4f4f4cefe",
            "635869f8adeb4198ae80bfff83025c4f",
            "49c6d9066f2c420eadf1da741600778a",
            "c9fe4c230bfb47098c1de7ef2d7621e9",
            "a299f18b2a0c44d1b6d9193c2b4c8ca3",
            "fe7a7370d8e04ba6984aed9fc96ed650",
            "20c6a9e746e8424d9108fef18fc625eb",
            "d596b46fb7084cafbe19ca93cdfa7533",
            "e73ca9dad0b74d828ec7c3c0100be722",
            "acdf75b484ff4cada055b220a6038e65",
            "41aedc6019454be1841a40740b581568",
            "153c7f4034c34288b17fa5f754778dd4",
            "d35fb24ff3934fa29d69954dd3ab0045",
            "4edebb16915248d79a96f4bc113c35ec",
            "57b07a580bf645fe8aa764ce5d5d56ee",
            "7df58a727267482e96e8bb3850954637",
            "117b7edc346549b886509f39496e6c8e",
            "beb6915eb4c64b1bbe7e5168420ea748",
            "e3f20ae03fec4cd5b23f54efd25cd448",
            "91d90b3589d34504b86540503bc5c045",
            "af61ae20f0c54fb39031ae8057e2a10d",
            "7aa3cd9b66834a78a116e07300dbf9b8",
            "99f81bf8fe254674aa78a32d2f574fd9",
            "cc540a2aa217407badcece6177f9ff8b",
            "7846707bd8c040e7a3157d61d1ccc737",
            "89495cabcbfb4086b2fd27c2b4610a25",
            "a3013b2ba71040958575ccab47c683c7"
          ]
        },
        "id": "_CX3wkove7Tf",
        "outputId": "9e1916cb-edec-4864-ffb9-23b7babe6819"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db58dc77bafb48229929c12720ea717f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe7a7370d8e04ba6984aed9fc96ed650",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "117b7edc346549b886509f39496e6c8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Changing model dtype to torch.float16\n",
            "Moving model to device:  cuda\n",
            "Modell in float16 auf GPU – konsistente Dtypes.\n"
          ]
        }
      ],
      "source": [
        "drive_dir = \"/content/drive/MyDrive/master_thesis/models\"\n",
        "\n",
        "import json, torch\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
        "\n",
        "with open(f\"{drive_dir}/config.json\") as f:\n",
        "    cfg_dict = json.load(f)\n",
        "\n",
        "cfg = HookedTransformerConfig.from_dict(cfg_dict)\n",
        "cfg.dtype = torch.float16\n",
        "\n",
        "model = HookedTransformer(cfg)\n",
        "\n",
        "state = torch.load(f\"{drive_dir}/pytorch_model.bin\", map_location=\"cpu\")\n",
        "model.load_state_dict(state)\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    model = model.to(torch.float16).to(\"cuda\")\n",
        "\n",
        "print(\"Modell in float16 auf GPU – konsistente Dtypes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2dANviB92FB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from typing import Dict, Any, Union, Optional, List\n",
        "\n",
        "\n",
        "def new_test_prompt(\n",
        "    prompt: str,\n",
        "    answer: Union[str, List[str]],\n",
        "    model,\n",
        "    relation_name: str,\n",
        "    json_output_folder: str,\n",
        "    prepend_space_to_answer: bool = True,\n",
        "    print_details: bool = True,\n",
        "    prepend_bos: Optional[bool] = False,\n",
        "    top_k: int = 10,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Lässt das Modell autoregressiv weiter‑dekodieren und evaluiert dabei\n",
        "    Top‑1‑ und Top‑10‑Accuracy auf Token‑Ebene.\n",
        "\n",
        "    Rückgabe:\n",
        "        {\n",
        "            \"top_1_accuracy\":  ...,\n",
        "            \"top_10_accuracy\": ...,\n",
        "            \"first_token_prob\": ...,\n",
        "            \"second_token_prob\": ...,\n",
        "            \"is_correct\":       True/False\n",
        "        }\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Ordner & Pfad für JSON‑Logging vorbereiten\n",
        "\n",
        "    os.makedirs(json_output_folder, exist_ok=True)\n",
        "    json_path = os.path.join(\n",
        "        json_output_folder, relation_name.replace(\" \", \"_\").lower() + \".json\"\n",
        "    )\n",
        "\n",
        "\n",
        "    # Referenz‑Antwort vorbereiten\n",
        "\n",
        "    answers: List[str] = [answer] if isinstance(answer, str) else list(answer)\n",
        "    if prepend_space_to_answer:\n",
        "        answers = [a if a.startswith(\" \") else \" \" + a for a in answers]\n",
        "\n",
        "    gold_answer = answers[0]\n",
        "    gold_answer_ids = model.to_tokens(gold_answer, prepend_bos=False)[0]\n",
        "    gold_answer_str_tokens = model.to_str_tokens(gold_answer, prepend_bos=False)\n",
        "\n",
        "\n",
        "    # Prompt tokenisieren\n",
        "\n",
        "    context_ids = model.to_tokens(prompt, prepend_bos=prepend_bos)[0].clone()\n",
        "    _ = model.to_str_tokens(prompt, prepend_bos=prepend_bos)\n",
        "\n",
        "\n",
        "    # Autoregressive Schleife\n",
        "\n",
        "    first_token_prob = second_token_prob = None\n",
        "    top_1_correct = top_10_correct = 0\n",
        "    first_token_correct: Optional[bool] = None   # Flag, ob 1. Token korrekt war\n",
        "    entries = []\n",
        "\n",
        "    for pos in range(len(gold_answer_ids)):\n",
        "\n",
        "        # Forward‑Pass\n",
        "        logits = model(context_ids.unsqueeze(0))\n",
        "        probs = logits.softmax(dim=-1)\n",
        "\n",
        "        next_token_logits = logits[0, -1]\n",
        "        next_token_probs = probs[0, -1]\n",
        "\n",
        "        sorted_probs, sorted_indices = next_token_probs.sort(descending=True)\n",
        "\n",
        "        # Wahrscheinlichkeiten der Top‑2‑Tokens merken\n",
        "        if first_token_prob is None:\n",
        "            first_token_prob = sorted_probs[0].item()\n",
        "            second_token_prob = sorted_probs[1].item()\n",
        "\n",
        "        # Predicted Token + Vergleich mit Gold\n",
        "        predicted_token_id = sorted_indices[0].item()\n",
        "        predicted_token_str = model.to_string(predicted_token_id)\n",
        "\n",
        "        gold_token_id = gold_answer_ids[pos].item()\n",
        "        gold_token_str = gold_answer_str_tokens[pos]\n",
        "\n",
        "        #print(\"Indizies top k\",sorted_indices[:top_k])\n",
        "\n",
        "        # Accuracy‑Zählung\n",
        "        if predicted_token_id == gold_token_id:\n",
        "            top_1_correct += 1\n",
        "            #print(predicted_token_str, gold_token_str)\n",
        "        if (sorted_indices[:top_k] == gold_token_id).any():\n",
        "            top_10_correct += 1\n",
        "\n",
        "\n",
        "        # Flag für korrektes 1. Token setzen\n",
        "        if pos == 0:\n",
        "            first_token_correct = (predicted_token_id == gold_token_id)\n",
        "\n",
        "        # Logging‑Eintrag\n",
        "        entries.append(\n",
        "            {\n",
        "                \"prompt\": prompt,\n",
        "                \"generated_prefix\": model.to_string(context_ids.tolist()),\n",
        "                \"gold_token\": gold_token_str,\n",
        "                \"predicted_top1_token\": predicted_token_str,\n",
        "                \"token_pos_in_answer\": pos,\n",
        "                \"gold_logit\": next_token_logits[gold_token_id].item(),\n",
        "                \"gold_prob_percent\": round(next_token_probs[gold_token_id].item() * 100, 2),\n",
        "                \"first_token_prob\": first_token_prob,\n",
        "                \"second_token_prob\": second_token_prob,\n",
        "                \"is_top_1\": int(predicted_token_id == gold_token_id),\n",
        "                \"top_k_predictions\": [\n",
        "                    {\n",
        "                        \"rank\": k,\n",
        "                        \"token\": model.to_string(sorted_indices[k].item()),\n",
        "                        \"logit\": next_token_logits[sorted_indices[k]].item(),\n",
        "                        \"probability_percent\": round(sorted_probs[k].item() * 100, 2),\n",
        "                    }\n",
        "                    for k in range(min(top_k, sorted_indices.shape[0]))\n",
        "                ],\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Kontext erweitern (Greedy)\n",
        "        context_ids = torch.cat(\n",
        "            [\n",
        "                context_ids,\n",
        "                torch.tensor(\n",
        "                    [predicted_token_id],\n",
        "                    dtype=context_ids.dtype,\n",
        "                    device=context_ids.device,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        if print_details:\n",
        "            print(\n",
        "                f\"[Step {pos}] Gold: |{gold_token_str}| \"\n",
        "                f\"Pred: |{predicted_token_str}|  \"\n",
        "                f\"Top‑1 Prob: {sorted_probs[0].item():.2%}\"\n",
        "            )\n",
        "\n",
        "\n",
        "    # Accuracy berechnen & Ergebnisse speichern\n",
        "\n",
        "    total_tokens = len(gold_answer_ids)\n",
        "\n",
        "    # Falls das 1. Sub‑Token falsch ist, setzen wir nur Top‑1‑Accuracy auf 0\n",
        "    if first_token_correct is False:\n",
        "        top_1_accuracy = 0.0\n",
        "        is_correct_word = False\n",
        "    else:\n",
        "        top_1_accuracy = 100 * top_1_correct / total_tokens\n",
        "        is_correct_word = top_1_correct == total_tokens\n",
        "\n",
        "    # Top‑10‑Accuracy wird immer unabhängig vom ersten Token berechnet\n",
        "    top_10_accuracy = 100 * top_10_correct / total_tokens\n",
        "\n",
        "\n",
        "    try:\n",
        "        with open(json_path, \"r\", encoding=\"utf-8\") as fh:\n",
        "            history = json.load(fh)\n",
        "            if not isinstance(history, list):\n",
        "                history = []\n",
        "    except FileNotFoundError:\n",
        "        history = []\n",
        "\n",
        "    history.extend(entries)\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as fh:\n",
        "        json.dump(history, fh, indent=2, ensure_ascii=False)\n",
        "\n",
        "    return {\n",
        "        \"top_1_accuracy\": top_1_accuracy,\n",
        "        \"top_10_accuracy\": top_10_accuracy,\n",
        "        \"first_token_prob\": first_token_prob,\n",
        "        \"second_token_prob\": second_token_prob,\n",
        "        \"is_correct\": is_correct_word,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCPOyT0dXHAt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from typing import Dict, Any, Union, Optional, List\n",
        "\n",
        "\n",
        "def new_test_prompt_(\n",
        "\n",
        "    prompt: str,\n",
        "    answer: Union[str, List[str]],\n",
        "    model,\n",
        "    relation_name: str,\n",
        "    #json_output_folder: str,\n",
        "    prepend_space_to_answer: bool = True,\n",
        "    print_details: bool = True,\n",
        "    prepend_bos: Optional[bool] = False,\n",
        "    top_k: int = 10,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Hat genau dieselbe Funktion wie oben, nur werden die Logits nicht in den JSON-Daten gespeichert.\n",
        "    Wird ausschließlich zur Evaluation der Templates verwendet.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Ordner & Pfad für JSON‑Logging vorbereiten\n",
        "\n",
        "    #os.makedirs(json_output_folder, exist_ok=True)\n",
        "    #json_path = os.path.join(\n",
        "    #    json_output_folder, relation_name.replace(\" \", \"_\").lower() + \".json\"\n",
        "    #)\n",
        "\n",
        "\n",
        "    # Referenz‑Antwort vorbereiten\n",
        "\n",
        "    answers: List[str] = [answer] if isinstance(answer, str) else list(answer)\n",
        "    if prepend_space_to_answer:\n",
        "        answers = [a if a.startswith(\" \") else \" \" + a for a in answers]\n",
        "\n",
        "    gold_answer = answers[0]\n",
        "    gold_answer_ids = model.to_tokens(gold_answer, prepend_bos=False)[0]\n",
        "    gold_answer_str_tokens = model.to_str_tokens(gold_answer, prepend_bos=False)\n",
        "\n",
        "\n",
        "    # Prompt tokenisieren\n",
        "\n",
        "    context_ids = model.to_tokens(prompt, prepend_bos=prepend_bos)[0].clone()\n",
        "    _ = model.to_str_tokens(prompt, prepend_bos=prepend_bos)\n",
        "\n",
        "\n",
        "    # Autoregressive Schleife\n",
        "\n",
        "    first_token_prob = second_token_prob = None\n",
        "    top_1_correct = top_10_correct = 0\n",
        "    first_token_correct: Optional[bool] = None   # Flag, ob 1. Token korrekt war\n",
        "    #entries = []\n",
        "\n",
        "    for pos in range(len(gold_answer_ids)):\n",
        "\n",
        "        # Forward‑Pass\n",
        "        logits = model(context_ids.unsqueeze(0))\n",
        "        probs = logits.softmax(dim=-1)\n",
        "\n",
        "        next_token_logits = logits[0, -1]\n",
        "        next_token_probs = probs[0, -1]\n",
        "\n",
        "        sorted_probs, sorted_indices = next_token_probs.sort(descending=True)\n",
        "\n",
        "        # Wahrscheinlichkeiten der Top‑2‑Tokens merken\n",
        "        if first_token_prob is None:\n",
        "            first_token_prob = sorted_probs[0].item()\n",
        "            second_token_prob = sorted_probs[1].item()\n",
        "\n",
        "        # Predicted Token + Vergleich mit Gold\n",
        "        predicted_token_id = sorted_indices[0].item()\n",
        "        predicted_token_str = model.to_string(predicted_token_id)\n",
        "\n",
        "        gold_token_id = gold_answer_ids[pos].item()\n",
        "        gold_token_str = gold_answer_str_tokens[pos]\n",
        "\n",
        "\n",
        "\n",
        "        # Accuracy‑Zählung\n",
        "        if predicted_token_id == gold_token_id:\n",
        "            top_1_correct += 1\n",
        "            #print(predicted_token_str, gold_token_str)\n",
        "        if (sorted_indices[:top_k] == gold_token_id).any():\n",
        "            top_10_correct += 1\n",
        "\n",
        "\n",
        "        # Flag für korrektes 1. Token setzen\n",
        "        if pos == 0:\n",
        "            first_token_correct = (predicted_token_id == gold_token_id)\n",
        "\n",
        "\n",
        "        \"\"\"entries.append(\n",
        "            {\n",
        "                \"prompt\": prompt,\n",
        "                \"generated_prefix\": model.to_string(context_ids.tolist()),\n",
        "                \"gold_token\": gold_token_str,\n",
        "                \"predicted_top1_token\": predicted_token_str,\n",
        "                \"token_pos_in_answer\": pos,\n",
        "                \"gold_logit\": next_token_logits[gold_token_id].item(),\n",
        "                \"gold_prob_percent\": round(next_token_probs[gold_token_id].item() * 100, 2),\n",
        "                \"first_token_prob\": first_token_prob,\n",
        "                \"second_token_prob\": second_token_prob,\n",
        "                \"is_top_1\": int(predicted_token_id == gold_token_id),\n",
        "                \"top_k_predictions\": [\n",
        "                    {\n",
        "                        \"rank\": k,\n",
        "                        \"token\": model.to_string(sorted_indices[k].item()),\n",
        "                        \"logit\": next_token_logits[sorted_indices[k]].item(),\n",
        "                        \"probability_percent\": round(sorted_probs[k].item() * 100, 2),\n",
        "                    }\n",
        "                    for k in range(min(top_k, sorted_indices.shape[0]))\n",
        "                ],\n",
        "            }\n",
        "        )\n",
        "        \"\"\"\n",
        "        # Kontext erweitern (Greedy)\n",
        "        context_ids = torch.cat(\n",
        "            [\n",
        "                context_ids,\n",
        "                torch.tensor(\n",
        "                    [predicted_token_id],\n",
        "                    dtype=context_ids.dtype,\n",
        "                    device=context_ids.device,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        if print_details:\n",
        "            print(\n",
        "                f\"[Step {pos}] Gold: |{gold_token_str}| \"\n",
        "                f\"Pred: |{predicted_token_str}|  \"\n",
        "                f\"Top‑1 Prob: {sorted_probs[0].item():.2%}\"\n",
        "            )\n",
        "\n",
        "\n",
        "    # Accuracy berechnen & Ergebnisse speichern\n",
        "\n",
        "    total_tokens = len(gold_answer_ids)\n",
        "\n",
        "    # Falls das 1. Sub‑Token falsch ist, setzen wir nur Top‑1‑Accuracy auf 0\n",
        "    if first_token_correct is False:\n",
        "        top_1_accuracy = 0.0\n",
        "        is_correct_word = False\n",
        "    else:\n",
        "        top_1_accuracy = 100 * top_1_correct / total_tokens\n",
        "        is_correct_word = top_1_correct == total_tokens\n",
        "\n",
        "    # Top‑10‑Accuracy wird immer unabhängig vom ersten Token berechnet\n",
        "    top_10_accuracy = 100 * top_10_correct / total_tokens\n",
        "\n",
        "    # JSON‑Historie anhängen\n",
        "    \"\"\"try:\n",
        "        with open(json_path, \"r\", encoding=\"utf-8\") as fh:\n",
        "            history = json.load(fh)\n",
        "            if not isinstance(history, list):\n",
        "                history = []\n",
        "    except FileNotFoundError:\n",
        "        history = []\n",
        "\n",
        "    history.extend(entries)\n",
        "    with open(json_path, \"w\", encoding=\"utf-8\") as fh:\n",
        "        json.dump(history, fh, indent=2, ensure_ascii=False)\n",
        "    \"\"\"\n",
        "\n",
        "    return {\n",
        "        \"top_1_accuracy\": top_1_accuracy,\n",
        "        \"top_10_accuracy\": top_10_accuracy,\n",
        "        \"first_token_prob\": first_token_prob,\n",
        "        \"second_token_prob\": second_token_prob,\n",
        "        \"is_correct\": is_correct_word,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml9QOXxkfAJp"
      },
      "outputs": [],
      "source": [
        "#root_path   = \"/content/drive/MyDrive/master_thesis/dataset_multilingual/linguistic/de\"\n",
        "#result_root = os.path.join(root_path, \"result_new_t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjVSSskOXa7t",
        "outputId": "334ead27-71ed-4d31-d314-48eaa1c79700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step 0] Gold: | be| Pred: | end|  Top‑1 Prob: 11.88%\n",
            "[Step 1] Gold: |endet| Pred: |g|  Top‑1 Prob: 83.25%\n",
            "[Step 2] Gold: |–| Pred: |ült|  Top‑1 Prob: 99.90%\n",
            "[Step 3] Gold: |–| Pred: |ig|  Top‑1 Prob: 99.90%\n",
            "[Step 4] Gold: |–| Pred: |.\n",
            "|  Top‑1 Prob: 91.26%\n",
            "Stop‑Token '.' erreicht – Generation beendet.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'top_1_accuracy': 0.0,\n",
              " 'top_10_accuracy': 0.0,\n",
              " 'first_token_prob': 0.11883544921875,\n",
              " 'second_token_prob': 0.10162353515625,\n",
              " 'is_correct': False}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#new_test_prompt(\"Das Gegenteil von ordentlich ist nachlässig.\\nDas Gegenteil von anfänglich ist\",\" beendet\", model, \"adjective_antonym_1shot\", result_root )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_Jhowt1oyzP"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_json_files(directory: str, selected_category: str, selected_relation: str) -> Dict[str, List[Dict]]:\n",
        "    \"\"\"\n",
        "    Load JSON files from the specified directory.\n",
        "\n",
        "    Args:\n",
        "        directory (str): Directory containing the JSON files.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary where keys are relation names and values are lists of data entries.\n",
        "    \"\"\"\n",
        "    data = {}\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            #print(file)\n",
        "            if file.endswith(\".json\"):\n",
        "                path = os.path.join(root, file)\n",
        "                #print(path)\n",
        "                with open(path, 'r') as f:\n",
        "                    category = os.path.basename(root)\n",
        "                    #print(\"categorie\",category)\n",
        "                    if category == selected_category or not selected_category:\n",
        "                        relation = os.path.basename(file).replace('.json', '')\n",
        "\n",
        "                        if relation == selected_relation or not selected_relation:\n",
        "                            if relation not in data:\n",
        "                                data[relation] = []\n",
        "                            data[relation].append(json.load(f))\n",
        "    return data\n",
        "\n",
        "\n",
        "def parse_samples(data: Dict[str, List[Dict]]) -> Tuple[List[str], List[str]]:\n",
        "    facts = []\n",
        "    targets = []\n",
        "    sentences = []\n",
        "    subjects = []\n",
        "    for entries in data:\n",
        "        #for entry in entries:\n",
        "        prompt_templates = entries['prompt_templates']\n",
        "        samples = entries['samples']\n",
        "\n",
        "        for sample in samples:\n",
        "            subject = sample['subject']\n",
        "            obj = \" \" + sample['object']\n",
        "\n",
        "\n",
        "            #for template in prompt_templates:  # Iterate through multiple templates\n",
        "                #fact = template.format(subject)\n",
        "            subjects.append(subject)\n",
        "            targets.append(obj)\n",
        "            #sentences.append(fact + obj)\n",
        "            # fact = prompt_templates.format(subject)\n",
        "            # facts.append(fact)\n",
        "            # targets.append(obj)\n",
        "    return prompt_templates, subjects, targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMR_NHiupX_h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "def calculate_average_accuracy(data, model, relation_name, permutation_name, base_output_dir):\n",
        "\n",
        "    \"\"\"Berechnet die durchschnittliche Top-1- und Top-10-Accuracy.\n",
        "    Speichert automatisch Logits in einem passenden Ordner.\n",
        "\n",
        "    Args:\n",
        "        data (dict): Die geladenen Beispieldaten.\n",
        "        model: Das Sprachmodell.\n",
        "        relation_name (str): z. B. \"adj_superlative\"\n",
        "        permutation_name (str): z. B. \"permutation_2\"\n",
        "        base_output_dir (str): Basisverzeichnis für alle Resultate (z. B. \"…/result/logits/\")\n",
        "\n",
        "    Returns:\n",
        "        dict mit average_top_1_accuracy und average_top_10_accuracy.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    total_top_1_accuracy = 0\n",
        "    total_top_10_accuracy = 0\n",
        "    total_examples = 0\n",
        "\n",
        "    # Zielverzeichnis für Logits\n",
        "    #json_output_folder = os.path.join(base_output_dir, permutation_name, relation_name)\n",
        "\n",
        "\n",
        "    os.makedirs(base_output_dir, exist_ok=True)\n",
        "\n",
        "    relation_base = relation_name.rsplit(\"_\", 1)[0]\n",
        "    json_output_folder = os.path.join(\n",
        "         base_output_dir,\n",
        "         relation_base\n",
        "     )\n",
        "    os.makedirs(json_output_folder, exist_ok=True)\n",
        "\n",
        "    for key, value in data.items():\n",
        "        prompt_templates, subjects, targets = parse_samples(value)\n",
        "\n",
        "        for subj, target in zip(subjects, targets):\n",
        "            for template in prompt_templates:\n",
        "                prompt = template.format(subj)\n",
        "\n",
        "                result = new_test_prompt(\n",
        "                    prompt=prompt,\n",
        "                    answer=target,\n",
        "                    model=model,\n",
        "                    relation_name=relation_name,\n",
        "                    json_output_folder=json_output_folder,  # automatisch generiert!\n",
        "                    prepend_space_to_answer=True,\n",
        "                    prepend_bos=False,\n",
        "                    print_details=False\n",
        "                )\n",
        "\n",
        "                total_top_1_accuracy += result[\"top_1_accuracy\"]\n",
        "                total_top_10_accuracy += result[\"top_10_accuracy\"]\n",
        "                total_examples += 1\n",
        "\n",
        "    average_top_1_accuracy = total_top_1_accuracy / total_examples\n",
        "    average_top_10_accuracy = total_top_10_accuracy / total_examples\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(f\"Dauer: {end_time - start_time:.2f}s | Beispiele: {total_examples}\")\n",
        "    return {\n",
        "        \"average_top_1_accuracy\": average_top_1_accuracy,\n",
        "        \"average_top_10_accuracy\": average_top_10_accuracy,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwqrSm-Tpbey"
      },
      "outputs": [],
      "source": [
        "def save_accuracy_to_json(average_accuracies: dict, relation_name: str, output_folder: str) -> None:\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    filename = f\"accuracy_{relation_name.replace(' ', '_').lower()}.json\"\n",
        "    path = os.path.join(output_folder, filename)\n",
        "\n",
        "    accuracy_data = {\n",
        "        \"relation\": relation_name,\n",
        "        \"average_top_1_accuracy\": round(average_accuracies.get(\"average_top_1_accuracy\", 0), 2),\n",
        "        \"average_top_10_accuracy\": round(average_accuracies.get(\"average_top_10_accuracy\", 0), 2)\n",
        "    }\n",
        "\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(accuracy_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Accuracy gespeichert unter: {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSe2wz3XI173",
        "outputId": "7c131d9b-7f22-4e9d-a821-91cd744f1698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "person_band_lead_singer_3shot.json\n",
            "Dauer: 4.73s | Beispiele: 21\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_band_lead_singer/accuracy_person_band_lead_singer_3shot.json\n",
            "fertig mit accuraccy_person_band_lead_singer_3shot.json\n",
            "person_plays_position_in_sport_3shot.json\n",
            "Dauer: 306.75s | Beispiele: 952\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_position_in_sport/accuracy_person_plays_position_in_sport_3shot.json\n",
            "fertig mit accuraccy_person_plays_position_in_sport_3shot.json\n",
            "person_band_lead_singer_4shot.json\n",
            "Dauer: 4.77s | Beispiele: 21\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_band_lead_singer/accuracy_person_band_lead_singer_4shot.json\n",
            "fertig mit accuraccy_person_band_lead_singer_4shot.json\n",
            "person_plays_position_in_sport_4shot.json\n",
            "Dauer: 308.75s | Beispiele: 952\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_position_in_sport/accuracy_person_plays_position_in_sport_4shot.json\n",
            "fertig mit accuraccy_person_plays_position_in_sport_4shot.json\n",
            "country_capital_city_3shot.json\n",
            "Dauer: 4.12s | Beispiele: 22\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_capital_city/accuracy_country_capital_city_3shot.json\n",
            "fertig mit accuraccy_country_capital_city_3shot.json\n",
            "country_largest_city_3shot.json\n",
            "Dauer: 5.23s | Beispiele: 24\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_largest_city/accuracy_country_largest_city_3shot.json\n",
            "fertig mit accuraccy_country_largest_city_3shot.json\n",
            "person_mother_3shot.json\n",
            "Dauer: 733.06s | Beispiele: 994\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_mother/accuracy_person_mother_3shot.json\n",
            "fertig mit accuraccy_person_mother_3shot.json\n",
            "person_plays_pro_sport_3shot.json\n",
            "Dauer: 41.60s | Beispiele: 170\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_pro_sport/accuracy_person_plays_pro_sport_3shot.json\n",
            "fertig mit accuraccy_person_plays_pro_sport_3shot.json\n",
            "person_university_3shot.json\n",
            "Dauer: 40.47s | Beispiele: 80\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_university/accuracy_person_university_3shot.json\n",
            "fertig mit accuraccy_person_university_3shot.json\n",
            "person_band_lead_singer_5shot.json\n",
            "Dauer: 4.72s | Beispiele: 21\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_band_lead_singer/accuracy_person_band_lead_singer_5shot.json\n",
            "fertig mit accuraccy_person_band_lead_singer_5shot.json\n",
            "person_plays_position_in_sport_5shot.json\n",
            "Dauer: 308.29s | Beispiele: 952\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_position_in_sport/accuracy_person_plays_position_in_sport_5shot.json\n",
            "fertig mit accuraccy_person_plays_position_in_sport_5shot.json\n",
            "pokemon_evolutions_3shot.json\n",
            "Dauer: 10.29s | Beispiele: 44\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_pokemon_evolutions/accuracy_pokemon_evolutions_3shot.json\n",
            "fertig mit accuraccy_pokemon_evolutions_3shot.json\n",
            "presidents_birth_year_3shot.json\n",
            "Dauer: 5.17s | Beispiele: 19\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_presidents_birth_year/accuracy_presidents_birth_year_3shot.json\n",
            "fertig mit accuraccy_presidents_birth_year_3shot.json\n",
            "presidents_election_year_3shot.json\n",
            "Dauer: 5.18s | Beispiele: 19\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_presidents_election_year/accuracy_presidents_election_year_3shot.json\n",
            "fertig mit accuraccy_presidents_election_year_3shot.json\n",
            "product_by_company_3shot.json\n",
            "Dauer: 67.22s | Beispiele: 522\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_product_by_company/accuracy_product_by_company_3shot.json\n",
            "fertig mit accuraccy_product_by_company_3shot.json\n",
            "star_constellation_3shot.json\n",
            "Dauer: 80.44s | Beispiele: 362\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_star_constellation/accuracy_star_constellation_3shot.json\n",
            "fertig mit accuraccy_star_constellation_3shot.json\n",
            "superhero_archnemesis_3shot.json\n",
            "Dauer: 24.37s | Beispiele: 96\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_superhero_archnemesis/accuracy_superhero_archnemesis_3shot.json\n",
            "fertig mit accuraccy_superhero_archnemesis_3shot.json\n",
            "country_capital_city_7shot.json\n",
            "Dauer: 4.57s | Beispiele: 22\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_capital_city/accuracy_country_capital_city_7shot.json\n",
            "fertig mit accuraccy_country_capital_city_7shot.json\n",
            "country_largest_city_7shot.json\n",
            "Dauer: 4.99s | Beispiele: 24\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_largest_city/accuracy_country_largest_city_7shot.json\n",
            "fertig mit accuraccy_country_largest_city_7shot.json\n",
            "person_mother_7shot.json\n",
            "Dauer: 756.97s | Beispiele: 994\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_mother/accuracy_person_mother_7shot.json\n",
            "fertig mit accuraccy_person_mother_7shot.json\n",
            "person_plays_pro_sport_7shot.json\n",
            "Dauer: 42.39s | Beispiele: 170\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_pro_sport/accuracy_person_plays_pro_sport_7shot.json\n",
            "fertig mit accuraccy_person_plays_pro_sport_7shot.json\n",
            "person_university_7shot.json\n",
            "Dauer: 40.73s | Beispiele: 80\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_university/accuracy_person_university_7shot.json\n",
            "fertig mit accuraccy_person_university_7shot.json\n",
            "pokemon_evolutions_7shot.json\n",
            "Dauer: 10.49s | Beispiele: 44\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_pokemon_evolutions/accuracy_pokemon_evolutions_7shot.json\n",
            "fertig mit accuraccy_pokemon_evolutions_7shot.json\n",
            "presidents_birth_year_7shot.json\n",
            "Dauer: 5.19s | Beispiele: 19\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_presidents_birth_year/accuracy_presidents_birth_year_7shot.json\n",
            "fertig mit accuraccy_presidents_birth_year_7shot.json\n",
            "presidents_election_year_7shot.json\n",
            "Dauer: 5.19s | Beispiele: 19\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_presidents_election_year/accuracy_presidents_election_year_7shot.json\n",
            "fertig mit accuraccy_presidents_election_year_7shot.json\n",
            "product_by_company_7shot.json\n",
            "Dauer: 69.21s | Beispiele: 522\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_product_by_company/accuracy_product_by_company_7shot.json\n",
            "fertig mit accuraccy_product_by_company_7shot.json\n",
            "star_constellation_7shot.json\n",
            "Dauer: 82.11s | Beispiele: 362\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_star_constellation/accuracy_star_constellation_7shot.json\n",
            "fertig mit accuraccy_star_constellation_7shot.json\n",
            "superhero_archnemesis_7shot.json\n",
            "Dauer: 24.32s | Beispiele: 96\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_superhero_archnemesis/accuracy_superhero_archnemesis_7shot.json\n",
            "fertig mit accuraccy_superhero_archnemesis_7shot.json\n",
            "country_language_7shot.json\n",
            "Dauer: 4.32s | Beispiele: 24\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_language/accuracy_country_language_7shot.json\n",
            "fertig mit accuraccy_country_language_7shot.json\n",
            "city_in_country_7shot.json\n",
            "Dauer: 5.72s | Beispiele: 27\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_city_in_country/accuracy_city_in_country_7shot.json\n",
            "fertig mit accuraccy_city_in_country_7shot.json\n",
            "company_ceo_7shot.json\n",
            "Dauer: 132.20s | Beispiele: 298\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_company_ceo/accuracy_company_ceo_7shot.json\n",
            "fertig mit accuraccy_company_ceo_7shot.json\n",
            "company_hq_7shot.json\n",
            "Dauer: 170.92s | Beispiele: 673\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_company_hq/accuracy_company_hq_7shot.json\n",
            "fertig mit accuraccy_company_hq_7shot.json\n",
            "country_currency_7shot.json\n",
            "Dauer: 7.47s | Beispiele: 25\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_currency/accuracy_country_currency_7shot.json\n",
            "fertig mit accuraccy_country_currency_7shot.json\n",
            "food_from_country_7shot.json\n",
            "Dauer: 6.57s | Beispiele: 28\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_food_from_country/accuracy_food_from_country_7shot.json\n",
            "fertig mit accuraccy_food_from_country_7shot.json\n",
            "landmark_in_country_7shot.json\n",
            "Dauer: 130.96s | Beispiele: 509\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_landmark_in_country/accuracy_landmark_in_country_7shot.json\n",
            "fertig mit accuraccy_landmark_in_country_7shot.json\n",
            "landmark_on_continent_7shot.json\n",
            "Dauer: 136.59s | Beispiele: 438\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_landmark_on_continent/accuracy_landmark_on_continent_7shot.json\n",
            "fertig mit accuraccy_landmark_on_continent_7shot.json\n",
            "person_band_lead_singer_7shot.json\n",
            "Dauer: 4.72s | Beispiele: 21\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_band_lead_singer/accuracy_person_band_lead_singer_7shot.json\n",
            "fertig mit accuraccy_person_band_lead_singer_7shot.json\n",
            "person_father_7shot.json\n",
            "Dauer: 730.24s | Beispiele: 991\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_father/accuracy_person_father_7shot.json\n",
            "fertig mit accuraccy_person_father_7shot.json\n",
            "person_occupation_7shot.json\n",
            "Dauer: 215.22s | Beispiele: 821\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_occupation/accuracy_person_occupation_7shot.json\n",
            "fertig mit accuraccy_person_occupation_7shot.json\n",
            "country_language_3shot.json\n",
            "Dauer: 4.24s | Beispiele: 24\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_language/accuracy_country_language_3shot.json\n",
            "fertig mit accuraccy_country_language_3shot.json\n",
            "person_plays_instrument_7shot.json\n",
            "Dauer: 112.44s | Beispiele: 513\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_instrument/accuracy_person_plays_instrument_7shot.json\n",
            "fertig mit accuraccy_person_plays_instrument_7shot.json\n",
            "person_plays_position_in_sport_7shot.json\n",
            "Dauer: 315.63s | Beispiele: 952\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_position_in_sport/accuracy_person_plays_position_in_sport_7shot.json\n",
            "fertig mit accuraccy_person_plays_position_in_sport_7shot.json\n",
            "superhero_person_7shot.json\n",
            "Dauer: 26.05s | Beispiele: 100\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_superhero_person/accuracy_superhero_person_7shot.json\n",
            "fertig mit accuraccy_superhero_person_7shot.json\n",
            "city_in_country_3shot.json\n",
            "Dauer: 5.66s | Beispiele: 27\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_city_in_country/accuracy_city_in_country_3shot.json\n",
            "fertig mit accuraccy_city_in_country_3shot.json\n",
            "company_ceo_3shot.json\n",
            "Dauer: 130.32s | Beispiele: 298\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_company_ceo/accuracy_company_ceo_3shot.json\n",
            "fertig mit accuraccy_company_ceo_3shot.json\n",
            "company_hq_3shot.json\n",
            "Dauer: 164.82s | Beispiele: 673\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_company_hq/accuracy_company_hq_3shot.json\n",
            "fertig mit accuraccy_company_hq_3shot.json\n",
            "country_currency_3shot.json\n",
            "Dauer: 7.78s | Beispiele: 25\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_currency/accuracy_country_currency_3shot.json\n",
            "fertig mit accuraccy_country_currency_3shot.json\n",
            "food_from_country_3shot.json\n",
            "Dauer: 6.41s | Beispiele: 28\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_food_from_country/accuracy_food_from_country_3shot.json\n",
            "fertig mit accuraccy_food_from_country_3shot.json\n",
            "country_capital_city_10shot.json\n",
            "Dauer: 4.25s | Beispiele: 22\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_capital_city/accuracy_country_capital_city_10shot.json\n",
            "fertig mit accuraccy_country_capital_city_10shot.json\n",
            "country_largest_city_10shot.json\n",
            "Dauer: 4.96s | Beispiele: 24\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_largest_city/accuracy_country_largest_city_10shot.json\n",
            "fertig mit accuraccy_country_largest_city_10shot.json\n",
            "person_mother_10shot.json\n",
            "Dauer: 776.75s | Beispiele: 994\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_mother/accuracy_person_mother_10shot.json\n",
            "fertig mit accuraccy_person_mother_10shot.json\n",
            "person_plays_pro_sport_10shot.json\n",
            "Dauer: 43.15s | Beispiele: 170\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_pro_sport/accuracy_person_plays_pro_sport_10shot.json\n",
            "fertig mit accuraccy_person_plays_pro_sport_10shot.json\n",
            "person_university_10shot.json\n",
            "Dauer: 40.45s | Beispiele: 80\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_university/accuracy_person_university_10shot.json\n",
            "fertig mit accuraccy_person_university_10shot.json\n",
            "pokemon_evolutions_10shot.json\n",
            "Dauer: 10.56s | Beispiele: 44\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_pokemon_evolutions/accuracy_pokemon_evolutions_10shot.json\n",
            "fertig mit accuraccy_pokemon_evolutions_10shot.json\n",
            "presidents_birth_year_10shot.json\n",
            "Dauer: 5.35s | Beispiele: 19\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_presidents_birth_year/accuracy_presidents_birth_year_10shot.json\n",
            "fertig mit accuraccy_presidents_birth_year_10shot.json\n",
            "presidents_election_year_10shot.json\n",
            "Dauer: 5.24s | Beispiele: 19\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_presidents_election_year/accuracy_presidents_election_year_10shot.json\n",
            "fertig mit accuraccy_presidents_election_year_10shot.json\n",
            "product_by_company_10shot.json\n",
            "Dauer: 70.67s | Beispiele: 522\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_product_by_company/accuracy_product_by_company_10shot.json\n",
            "fertig mit accuraccy_product_by_company_10shot.json\n",
            "star_constellation_10shot.json\n",
            "Dauer: 83.89s | Beispiele: 362\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_star_constellation/accuracy_star_constellation_10shot.json\n",
            "fertig mit accuraccy_star_constellation_10shot.json\n",
            "superhero_archnemesis_10shot.json\n",
            "Dauer: 24.57s | Beispiele: 96\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_superhero_archnemesis/accuracy_superhero_archnemesis_10shot.json\n",
            "fertig mit accuraccy_superhero_archnemesis_10shot.json\n",
            "country_language_10shot.json\n",
            "Dauer: 4.36s | Beispiele: 24\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_language/accuracy_country_language_10shot.json\n",
            "fertig mit accuraccy_country_language_10shot.json\n",
            "city_in_country_10shot.json\n",
            "Dauer: 5.68s | Beispiele: 27\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_city_in_country/accuracy_city_in_country_10shot.json\n",
            "fertig mit accuraccy_city_in_country_10shot.json\n",
            "company_ceo_10shot.json\n",
            "Dauer: 133.24s | Beispiele: 298\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_company_ceo/accuracy_company_ceo_10shot.json\n",
            "fertig mit accuraccy_company_ceo_10shot.json\n",
            "company_hq_10shot.json\n",
            "Dauer: 173.95s | Beispiele: 673\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_company_hq/accuracy_company_hq_10shot.json\n",
            "fertig mit accuraccy_company_hq_10shot.json\n",
            "country_currency_10shot.json\n",
            "Dauer: 7.66s | Beispiele: 25\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_currency/accuracy_country_currency_10shot.json\n",
            "fertig mit accuraccy_country_currency_10shot.json\n",
            "food_from_country_10shot.json\n",
            "Dauer: 6.55s | Beispiele: 28\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_food_from_country/accuracy_food_from_country_10shot.json\n",
            "fertig mit accuraccy_food_from_country_10shot.json\n",
            "landmark_in_country_10shot.json\n",
            "Dauer: 132.88s | Beispiele: 509\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_landmark_in_country/accuracy_landmark_in_country_10shot.json\n",
            "fertig mit accuraccy_landmark_in_country_10shot.json\n",
            "landmark_on_continent_10shot.json\n",
            "Dauer: 138.72s | Beispiele: 438\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_landmark_on_continent/accuracy_landmark_on_continent_10shot.json\n",
            "fertig mit accuraccy_landmark_on_continent_10shot.json\n",
            "person_band_lead_singer_10shot.json\n",
            "Dauer: 4.88s | Beispiele: 21\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_band_lead_singer/accuracy_person_band_lead_singer_10shot.json\n",
            "fertig mit accuraccy_person_band_lead_singer_10shot.json\n",
            "person_father_10shot.json\n",
            "Dauer: 742.65s | Beispiele: 991\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_father/accuracy_person_father_10shot.json\n",
            "fertig mit accuraccy_person_father_10shot.json\n",
            "person_occupation_10shot.json\n",
            "Dauer: 219.33s | Beispiele: 821\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_occupation/accuracy_person_occupation_10shot.json\n",
            "fertig mit accuraccy_person_occupation_10shot.json\n",
            "person_plays_instrument_10shot.json\n",
            "Dauer: 114.57s | Beispiele: 513\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_instrument/accuracy_person_plays_instrument_10shot.json\n",
            "fertig mit accuraccy_person_plays_instrument_10shot.json\n",
            "person_plays_position_in_sport_10shot.json\n",
            "Dauer: 325.50s | Beispiele: 952\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_position_in_sport/accuracy_person_plays_position_in_sport_10shot.json\n",
            "fertig mit accuraccy_person_plays_position_in_sport_10shot.json\n",
            "superhero_person_10shot.json\n",
            "Dauer: 26.12s | Beispiele: 100\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_superhero_person/accuracy_superhero_person_10shot.json\n",
            "fertig mit accuraccy_superhero_person_10shot.json\n",
            "landmark_in_country_3shot.json\n",
            "Dauer: 127.75s | Beispiele: 509\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_landmark_in_country/accuracy_landmark_in_country_3shot.json\n",
            "fertig mit accuraccy_landmark_in_country_3shot.json\n",
            "landmark_on_continent_3shot.json\n",
            "Dauer: 133.76s | Beispiele: 438\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_landmark_on_continent/accuracy_landmark_on_continent_3shot.json\n",
            "fertig mit accuraccy_landmark_on_continent_3shot.json\n",
            "person_father_3shot.json\n",
            "Dauer: 707.97s | Beispiele: 991\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_father/accuracy_person_father_3shot.json\n",
            "fertig mit accuraccy_person_father_3shot.json\n",
            "person_occupation_3shot.json\n",
            "Dauer: 208.69s | Beispiele: 821\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_occupation/accuracy_person_occupation_3shot.json\n",
            "fertig mit accuraccy_person_occupation_3shot.json\n",
            "person_plays_instrument_3shot.json\n",
            "Dauer: 108.72s | Beispiele: 513\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_instrument/accuracy_person_plays_instrument_3shot.json\n",
            "fertig mit accuraccy_person_plays_instrument_3shot.json\n",
            "superhero_person_3shot.json\n",
            "Dauer: 25.82s | Beispiele: 100\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_superhero_person/accuracy_superhero_person_3shot.json\n",
            "fertig mit accuraccy_superhero_person_3shot.json\n",
            "country_capital_city_4shot.json\n",
            "Dauer: 4.30s | Beispiele: 22\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_capital_city/accuracy_country_capital_city_4shot.json\n",
            "fertig mit accuraccy_country_capital_city_4shot.json\n",
            "country_largest_city_4shot.json\n",
            "Dauer: 4.97s | Beispiele: 24\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_largest_city/accuracy_country_largest_city_4shot.json\n",
            "fertig mit accuraccy_country_largest_city_4shot.json\n",
            "person_mother_4shot.json\n",
            "Dauer: 742.07s | Beispiele: 994\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_mother/accuracy_person_mother_4shot.json\n",
            "fertig mit accuraccy_person_mother_4shot.json\n",
            "person_plays_pro_sport_4shot.json\n",
            "Dauer: 42.20s | Beispiele: 170\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_pro_sport/accuracy_person_plays_pro_sport_4shot.json\n",
            "fertig mit accuraccy_person_plays_pro_sport_4shot.json\n",
            "person_university_4shot.json\n",
            "Dauer: 40.18s | Beispiele: 80\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_university/accuracy_person_university_4shot.json\n",
            "fertig mit accuraccy_person_university_4shot.json\n",
            "pokemon_evolutions_4shot.json\n",
            "Dauer: 10.53s | Beispiele: 44\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_pokemon_evolutions/accuracy_pokemon_evolutions_4shot.json\n",
            "fertig mit accuraccy_pokemon_evolutions_4shot.json\n",
            "presidents_birth_year_4shot.json\n",
            "Dauer: 5.22s | Beispiele: 19\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_presidents_birth_year/accuracy_presidents_birth_year_4shot.json\n",
            "fertig mit accuraccy_presidents_birth_year_4shot.json\n",
            "presidents_election_year_4shot.json\n",
            "Dauer: 5.28s | Beispiele: 19\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_presidents_election_year/accuracy_presidents_election_year_4shot.json\n",
            "fertig mit accuraccy_presidents_election_year_4shot.json\n",
            "product_by_company_4shot.json\n",
            "Dauer: 67.26s | Beispiele: 522\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_product_by_company/accuracy_product_by_company_4shot.json\n",
            "fertig mit accuraccy_product_by_company_4shot.json\n",
            "star_constellation_4shot.json\n",
            "Dauer: 81.43s | Beispiele: 362\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_star_constellation/accuracy_star_constellation_4shot.json\n",
            "fertig mit accuraccy_star_constellation_4shot.json\n",
            "superhero_archnemesis_4shot.json\n",
            "Dauer: 24.21s | Beispiele: 96\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_superhero_archnemesis/accuracy_superhero_archnemesis_4shot.json\n",
            "fertig mit accuraccy_superhero_archnemesis_4shot.json\n",
            "country_language_4shot.json\n",
            "Dauer: 4.31s | Beispiele: 24\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_language/accuracy_country_language_4shot.json\n",
            "fertig mit accuraccy_country_language_4shot.json\n",
            "city_in_country_4shot.json\n",
            "Dauer: 5.73s | Beispiele: 27\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_city_in_country/accuracy_city_in_country_4shot.json\n",
            "fertig mit accuraccy_city_in_country_4shot.json\n",
            "company_ceo_4shot.json\n",
            "Dauer: 130.91s | Beispiele: 298\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_company_ceo/accuracy_company_ceo_4shot.json\n",
            "fertig mit accuraccy_company_ceo_4shot.json\n",
            "company_hq_4shot.json\n",
            "Dauer: 166.89s | Beispiele: 673\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_company_hq/accuracy_company_hq_4shot.json\n",
            "fertig mit accuraccy_company_hq_4shot.json\n",
            "country_currency_4shot.json\n",
            "Dauer: 7.48s | Beispiele: 25\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_currency/accuracy_country_currency_4shot.json\n",
            "fertig mit accuraccy_country_currency_4shot.json\n",
            "food_from_country_4shot.json\n",
            "Dauer: 6.51s | Beispiele: 28\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_food_from_country/accuracy_food_from_country_4shot.json\n",
            "fertig mit accuraccy_food_from_country_4shot.json\n",
            "landmark_in_country_4shot.json\n",
            "Dauer: 128.51s | Beispiele: 509\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_landmark_in_country/accuracy_landmark_in_country_4shot.json\n",
            "fertig mit accuraccy_landmark_in_country_4shot.json\n",
            "landmark_on_continent_4shot.json\n",
            "Dauer: 134.67s | Beispiele: 438\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_landmark_on_continent/accuracy_landmark_on_continent_4shot.json\n",
            "fertig mit accuraccy_landmark_on_continent_4shot.json\n",
            "person_father_4shot.json\n",
            "Dauer: 712.55s | Beispiele: 991\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_father/accuracy_person_father_4shot.json\n",
            "fertig mit accuraccy_person_father_4shot.json\n",
            "person_occupation_4shot.json\n",
            "Dauer: 211.14s | Beispiele: 821\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_occupation/accuracy_person_occupation_4shot.json\n",
            "fertig mit accuraccy_person_occupation_4shot.json\n",
            "person_plays_instrument_4shot.json\n",
            "Dauer: 109.32s | Beispiele: 513\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_instrument/accuracy_person_plays_instrument_4shot.json\n",
            "fertig mit accuraccy_person_plays_instrument_4shot.json\n",
            "superhero_person_4shot.json\n",
            "Dauer: 25.90s | Beispiele: 100\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_superhero_person/accuracy_superhero_person_4shot.json\n",
            "fertig mit accuraccy_superhero_person_4shot.json\n",
            "country_capital_city_5shot.json\n",
            "Dauer: 4.22s | Beispiele: 22\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_capital_city/accuracy_country_capital_city_5shot.json\n",
            "fertig mit accuraccy_country_capital_city_5shot.json\n",
            "country_largest_city_5shot.json\n",
            "Dauer: 4.99s | Beispiele: 24\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_largest_city/accuracy_country_largest_city_5shot.json\n",
            "fertig mit accuraccy_country_largest_city_5shot.json\n",
            "person_mother_5shot.json\n",
            "Dauer: 749.19s | Beispiele: 994\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_mother/accuracy_person_mother_5shot.json\n",
            "fertig mit accuraccy_person_mother_5shot.json\n",
            "person_plays_pro_sport_5shot.json\n",
            "Dauer: 42.57s | Beispiele: 170\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_pro_sport/accuracy_person_plays_pro_sport_5shot.json\n",
            "fertig mit accuraccy_person_plays_pro_sport_5shot.json\n",
            "person_university_5shot.json\n",
            "Dauer: 40.67s | Beispiele: 80\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_university/accuracy_person_university_5shot.json\n",
            "fertig mit accuraccy_person_university_5shot.json\n",
            "pokemon_evolutions_5shot.json\n",
            "Dauer: 10.41s | Beispiele: 44\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_pokemon_evolutions/accuracy_pokemon_evolutions_5shot.json\n",
            "fertig mit accuraccy_pokemon_evolutions_5shot.json\n",
            "presidents_birth_year_5shot.json\n",
            "Dauer: 5.20s | Beispiele: 19\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_presidents_birth_year/accuracy_presidents_birth_year_5shot.json\n",
            "fertig mit accuraccy_presidents_birth_year_5shot.json\n",
            "presidents_election_year_5shot.json\n",
            "Dauer: 5.19s | Beispiele: 19\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_presidents_election_year/accuracy_presidents_election_year_5shot.json\n",
            "fertig mit accuraccy_presidents_election_year_5shot.json\n",
            "product_by_company_5shot.json\n",
            "Dauer: 67.86s | Beispiele: 522\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_product_by_company/accuracy_product_by_company_5shot.json\n",
            "fertig mit accuraccy_product_by_company_5shot.json\n",
            "star_constellation_5shot.json\n",
            "Dauer: 81.90s | Beispiele: 362\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_star_constellation/accuracy_star_constellation_5shot.json\n",
            "fertig mit accuraccy_star_constellation_5shot.json\n",
            "superhero_archnemesis_5shot.json\n",
            "Dauer: 24.27s | Beispiele: 96\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_superhero_archnemesis/accuracy_superhero_archnemesis_5shot.json\n",
            "fertig mit accuraccy_superhero_archnemesis_5shot.json\n",
            "country_language_5shot.json\n",
            "Dauer: 4.42s | Beispiele: 24\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_language/accuracy_country_language_5shot.json\n",
            "fertig mit accuraccy_country_language_5shot.json\n",
            "city_in_country_5shot.json\n",
            "Dauer: 5.74s | Beispiele: 27\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_city_in_country/accuracy_city_in_country_5shot.json\n",
            "fertig mit accuraccy_city_in_country_5shot.json\n",
            "company_ceo_5shot.json\n",
            "Dauer: 131.89s | Beispiele: 298\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_company_ceo/accuracy_company_ceo_5shot.json\n",
            "fertig mit accuraccy_company_ceo_5shot.json\n",
            "company_hq_5shot.json\n",
            "Dauer: 168.63s | Beispiele: 673\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_company_hq/accuracy_company_hq_5shot.json\n",
            "fertig mit accuraccy_company_hq_5shot.json\n",
            "country_currency_5shot.json\n",
            "Dauer: 7.55s | Beispiele: 25\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_country_currency/accuracy_country_currency_5shot.json\n",
            "fertig mit accuraccy_country_currency_5shot.json\n",
            "food_from_country_5shot.json\n",
            "Dauer: 6.51s | Beispiele: 28\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_food_from_country/accuracy_food_from_country_5shot.json\n",
            "fertig mit accuraccy_food_from_country_5shot.json\n",
            "landmark_in_country_5shot.json\n",
            "Dauer: 130.38s | Beispiele: 509\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_landmark_in_country/accuracy_landmark_in_country_5shot.json\n",
            "fertig mit accuraccy_landmark_in_country_5shot.json\n",
            "landmark_on_continent_5shot.json\n",
            "Dauer: 137.22s | Beispiele: 438\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_landmark_on_continent/accuracy_landmark_on_continent_5shot.json\n",
            "fertig mit accuraccy_landmark_on_continent_5shot.json\n",
            "person_father_5shot.json\n",
            "Dauer: 718.69s | Beispiele: 991\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_father/accuracy_person_father_5shot.json\n",
            "fertig mit accuraccy_person_father_5shot.json\n",
            "person_occupation_5shot.json\n",
            "Dauer: 212.73s | Beispiele: 821\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_occupation/accuracy_person_occupation_5shot.json\n",
            "fertig mit accuraccy_person_occupation_5shot.json\n",
            "person_plays_instrument_5shot.json\n",
            "Dauer: 112.23s | Beispiele: 513\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_person_plays_instrument/accuracy_person_plays_instrument_5shot.json\n",
            "fertig mit accuraccy_person_plays_instrument_5shot.json\n",
            "superhero_person_5shot.json\n",
            "Dauer: 26.08s | Beispiele: 100\n",
            "Accuracy gespeichert unter: /content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es/result_10_accuracy/eval_accuracy/permutation_4/accuracy_superhero_person/accuracy_superhero_person_5shot.json\n",
            "fertig mit accuraccy_superhero_person_5shot.json\n",
            "Alle Accuracy Ferig\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Basisverzeichnisse\n",
        "root_path   =\"\"\n",
        "root_path   =\"/content/drive/MyDrive/master_thesis/dataset_multilingual/factual/es\"\n",
        "result_root = os.path.join(root_path, \"results\")\n",
        "logits_root = os.path.join(result_root, \"logits/permutation_0\")\n",
        "eval_root   = os.path.join(result_root, \"eval_accuracy\")\n",
        "\n",
        "# >>> Nur diese Permutation verarbeiten\n",
        "target_permutation = \"permutation_0\"\n",
        "\n",
        "perm_path = os.path.join(root_path, target_permutation)\n",
        "if not os.path.isdir(perm_path):\n",
        "    raise FileNotFoundError(f\"{perm_path} existiert nicht oder ist kein Ordner\")\n",
        "\n",
        "json_files = [f for f in os.listdir(perm_path) if f.endswith(\".json\")]\n",
        "\n",
        "\n",
        "for json_file in json_files:\n",
        "    print(json_file)\n",
        "    match = re.match(r\"(.+?)_(\\d+)shot\\.json\", json_file)\n",
        "    if not match:\n",
        "        continue\n",
        "\n",
        "    relation_base, shot = match.groups()\n",
        "\n",
        "    relation_name = f\"{relation_base}_{shot}shot\"\n",
        "\n",
        "    logits_output_path   = logits_root\n",
        "    accuracy_output_path = os.path.join(\n",
        "        eval_root,\n",
        "        target_permutation,\n",
        "        f\"accuracy_{relation_base}\"\n",
        "    )\n",
        "    os.makedirs(accuracy_output_path, exist_ok=True)\n",
        "\n",
        "    # Daten laden\n",
        "    data = load_json_files(root_path, target_permutation, relation_name)\n",
        "    #print(data)\n",
        "\n",
        "    average_accuracies = calculate_average_accuracy(\n",
        "        data=data,\n",
        "        model=model,\n",
        "        relation_name=relation_name,\n",
        "        permutation_name=target_permutation,\n",
        "        base_output_dir=logits_output_path\n",
        "    )\n",
        "\n",
        "\n",
        "    # Abspeichern\n",
        "    save_accuracy_to_json(average_accuracies, relation_name, accuracy_output_path)\n",
        "    print(f\"fertig mit accuraccy_{json_file}\")\n",
        "\n",
        "print(\"Alle Accuracy Ferig\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relation_name = \"city_in_country\"\n",
        "\n",
        "file_path_factual = \"/content/drive/MyDrive/master_thesis/data/data_en/factual_data/zero_shot_data\"\n",
        "data = load_json_files(file_path_factual, \"original_data\", relation_name)\n",
        "for key, value in data.items():\n",
        "    #sentences, facts, targets = parse_samples(value)\n",
        "    prompt_templates, subjects, targets = parse_samples(value)\n",
        "    print(subjects)\n",
        "    print(targets)\n",
        "    print(prompt_templates)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrwejqEZbOgt",
        "outputId": "0d22f11d-b2ba-4948-9c9d-ecdd2988d1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['New York City', 'Rio de Janeiro', 'Buenos Aires', 'Mexico City', 'São Paulo', 'Los Angeles', 'Saint Petersburg', 'San Francisco', 'Ho Chi Minh City', 'Kuala Lumpur', 'Abu Dhabi', 'Cape Town', 'New Delhi', 'Las Vegas', 'Hong Kong', 'Tel Aviv', 'Johannesburg', 'Santo Domingo', 'Port-au-Prince', 'Santiago de Chile', 'Panama City', 'Siem Reap', 'Casablanca', 'San Juan', 'Costa Rica', 'Addis Ababa', 'Punta Cana']\n",
            "[' United States', ' Brazil', ' Argentina', ' Mexico', ' Brazil', ' United States', ' Russia', ' United States', ' Vietnam', ' Malaysia', ' United Arab Emirates', ' South Africa', ' India', ' United States', ' China', ' Israel', ' South Africa', ' Dominican Republic', ' Haiti', ' Chile', ' Panama', ' Cambodia', ' Morocco', ' Puerto Rico', ' San José', ' Ethiopia', ' Dominican Republic']\n",
            "['{} is part of', '{} is in the country of']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5EsMqEE9GPA"
      },
      "outputs": [],
      "source": [
        "def evaluate_templates_overall(\n",
        "    subjects: List[str],\n",
        "    targets: List[str],\n",
        "    prompt_templates: List[str],\n",
        "    model,\n",
        "    second_token_threshold: float = 0.10\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Evaluate all prompt templates and determine the best one based on overall performance,\n",
        "    while identifying reliable and unreliable samples.\n",
        "\n",
        "    Args:\n",
        "        facts (list): List of facts (subject strings).\n",
        "        targets (list): List of corresponding targets (answers).\n",
        "        prompt_templates (list): List of prompt templates to test.\n",
        "        model: The language model to evaluate.\n",
        "        second_token_threshold (float): Maximum allowed probability for the second token.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with:\n",
        "            - template_scores: Overall scores and aggregated metrics for each template.\n",
        "            - best_template: The best template based on the overall score.\n",
        "            - best_template_metrics: Metrics for the best template.\n",
        "            - reliable_samples: List of reliable samples with their details.\n",
        "            - unreliable_samples: List of unreliable samples with their details.\n",
        "    \"\"\"\n",
        "    template_scores = {template: {\"first_token_prob_sum\": 0,\n",
        "                                  \"second_token_valid_count\": 0,\n",
        "                                  \"total_count\": 0} for template in prompt_templates}\n",
        "\n",
        "\n",
        "    reliable_samples = []\n",
        "    unreliable_samples = []\n",
        "\n",
        "    for subject, target in zip(subjects, targets):\n",
        "\n",
        "        sample_details = []\n",
        "\n",
        "        for template in prompt_templates:\n",
        "            # Format the fact using the template\n",
        "            is_reliable = False\n",
        "            prompt = template.format(subject)\n",
        "\n",
        "            # Evaluate the prompt\n",
        "            res = new_test_prompt_(\n",
        "                prompt=prompt,\n",
        "                answer=target,\n",
        "                model=model,\n",
        "                print_details=True  # Suppress detailed printing for bulk processing\n",
        "            )\n",
        "\n",
        "            # Update metrics for the template\n",
        "            if res[\"is_correct\"]:\n",
        "                template_scores[template][\"first_token_prob_sum\"] += res[\"first_token_prob\"]\n",
        "                template_scores[template][\"total_count\"] += 1\n",
        "                if res[\"second_token_prob\"] < second_token_threshold:\n",
        "                    template_scores[template][\"second_token_valid_count\"] += 1\n",
        "                    is_reliable = True\n",
        "            else:\n",
        "                template_scores[template][\"first_token_prob_sum\"] += 0\n",
        "                template_scores[template][\"total_count\"] += 1\n",
        "\n",
        "            # Collect sample details for each template\n",
        "            sample_details.append({\n",
        "                \"template\": template,\n",
        "                \"first_token_prob\": res[\"first_token_prob\"],\n",
        "                \"second_token_prob\": res[\"second_token_prob\"],\n",
        "                \"is_reliable\": res[\"second_token_prob\"] < second_token_threshold,\n",
        "            })\n",
        "\n",
        "            # Add sample to reliable or unreliable list\n",
        "            if is_reliable:\n",
        "                reliable_samples.append({\"subject\": subject, \"object\": target.strip()})\n",
        "            else:\n",
        "                unreliable_samples.append({\"subject\": subject, \"object\": target.strip()})\n",
        "\n",
        "    # Calculate average scores and reliability for each template\n",
        "    overall_scores = {}\n",
        "    for template, metrics in template_scores.items():\n",
        "        avg_first_token_prob = metrics[\"first_token_prob_sum\"] / metrics[\"total_count\"]\n",
        "        reliability = metrics[\"second_token_valid_count\"] / metrics[\"total_count\"]\n",
        "        overall_scores[template] = {\n",
        "            \"average_first_token_prob\": avg_first_token_prob,\n",
        "            \"reliability\": reliability,\n",
        "            \"overall_score\": avg_first_token_prob * reliability,  # Combined score\n",
        "        }\n",
        "\n",
        "    # Find the best template based on the overall score\n",
        "    best_template = max(overall_scores.items(), key=lambda x: x[1][\"overall_score\"])\n",
        "\n",
        "    return {\n",
        "        \"template_scores\": overall_scores,\n",
        "        \"best_template\": best_template[0],\n",
        "        \"best_template_metrics\": best_template[1],\n",
        "        \"reliable_samples\": reliable_samples,\n",
        "        \"unreliable_samples\": unreliable_samples,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6qL3ShTPbD21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_best_template_samples(\n",
        "    subjects: List[str],\n",
        "    targets: List[str],\n",
        "    best_template: str,\n",
        "    model,\n",
        "    first_token_threshold = 0.75,\n",
        "    second_token_threshold: float = 0.10\n",
        ") -> Dict[str, List[Dict]]:\n",
        "    \"\"\"\n",
        "    Evaluate reliable and unreliable samples using the best template.\n",
        "\n",
        "    Args:\n",
        "        facts (list): List of facts (subject strings).\n",
        "        targets (list): List of corresponding targets (answers).\n",
        "        best_template (str): The best template determined earlier.\n",
        "        model: The language model to evaluate.\n",
        "        second_token_threshold (float): Maximum allowed probability for the second token.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with:\n",
        "            - reliable_samples: List of reliable samples in the specified format.\n",
        "            - unreliable_samples: List of unreliable samples in the specified format.\n",
        "    \"\"\"\n",
        "    reliable_samples = []\n",
        "    unreliable_samples = []\n",
        "\n",
        "    for subject, target in zip(subjects, targets):\n",
        "        # Format the fact using the best template\n",
        "        prompt = best_template.format(subject)\n",
        "\n",
        "        # Evaluate the prompt\n",
        "        res = new_test_prompt(\n",
        "            prompt=prompt,\n",
        "            answer=target,\n",
        "            model=model,\n",
        "            print_details=False  # Suppress detailed printing for bulk processing\n",
        "        )\n",
        "\n",
        "        # Determine reliability based on second token probability\n",
        "        if res['is_correct'] == True and res[\"first_token_prob\"] > first_token_threshold and res[\"second_token_prob\"] < second_token_threshold:\n",
        "            reliable_samples.append({\"subject\": subject, \"object\": target.strip()})\n",
        "        else:\n",
        "            unreliable_samples.append({\"subject\": subject, \"object\": target.strip()})\n",
        "\n",
        "    return {\n",
        "        \"reliable_samples\": reliable_samples,\n",
        "        \"unreliable_samples\": unreliable_samples,\n",
        "    }"
      ],
      "metadata": {
        "id": "sKjGRDynWEWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=evaluate_templates_overall(subjects, targets, prompt_templates, model, second_token_threshold=0.10)\n",
        "\n",
        "\n",
        "print(\"Template Scores:\")\n",
        "for template, metrics in result[\"template_scores\"].items():\n",
        "    print(f\"Template: {template}\")\n",
        "    print(f\"  Average First Token Prob: {metrics['average_first_token_prob']:.2f}\")\n",
        "    print(f\"  Reliability: {metrics['reliability']:.2%}\")\n",
        "    print(f\"  Overall Score: {metrics['overall_score']:.2f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    print(f\"Best Template: {result['best_template']}\")\n",
        "    print(f\"Best Template Metrics: {result['best_template_metrics']}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_template_evaluation_to_json(result: dict, relation_name: str, output_folder: str) -> None:\n",
        "    \"\"\"\n",
        "    Speichert die Template-Evaluationsergebnisse in einer JSON-Datei.\n",
        "\n",
        "    Args:\n",
        "        result (dict): Das Ergebnis von evaluate_templates_overall().\n",
        "        relation_name (str): Name der Relation (für den Dateinamen).\n",
        "        output_folder (str): Zielordner zum Speichern der Datei.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    output_path = os.path.join(output_folder, f\"template_eval_{relation_name.replace(' ', '_').lower()}.json\")\n",
        "\n",
        "    data_to_save = {\n",
        "        \"relation\": relation_name,\n",
        "        \"template_scores\": result.get(\"template_scores\", {}),\n",
        "        \"best_template\": result.get(\"best_template\"),\n",
        "        \"best_template_metrics\": result.get(\"best_template_metrics\")\n",
        "    }\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data_to_save, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Evaluation gespeichert unter: {output_path}\")\n",
        "\n",
        "\n",
        "\n",
        "best_shots_scores=\"/content/drive/MyDrive/master_thesis/data/data_en/factual_data/zero_shot_data/best_template/best_template_file\"\n",
        "\n",
        "save_template_evaluation_to_json(\n",
        "    result=result,\n",
        "    relation_name=relation_name,\n",
        "    output_folder=best_shots_scores\n",
        ")"
      ],
      "metadata": {
        "id": "PkkdPQg-WIp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_template = result[\"best_template\"]\n",
        "print(f\"Best Template: {best_template}\")\n",
        "\n",
        "# Evaluate reliable and unreliable samples for the best template\n",
        "sample_evaluation_result = evaluate_best_template_samples(\n",
        "    subjects=subjects,\n",
        "    targets=targets,\n",
        "    best_template=best_template,\n",
        "    model=model,\n",
        "    first_token_threshold = 0.75,\n",
        "    second_token_threshold=0.10\n",
        ")"
      ],
      "metadata": {
        "id": "a6MsxthmWb-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int(f\"Reliable Examples: {sample_evaluation_result['reliable_samples']}\")\n",
        "print(f\"Unreliable Examples: {sample_evaluation_result['unreliable_samples']}\")"
      ],
      "metadata": {
        "id": "ohb4zIBlWexr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "117b7edc346549b886509f39496e6c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_beb6915eb4c64b1bbe7e5168420ea748",
              "IPY_MODEL_e3f20ae03fec4cd5b23f54efd25cd448",
              "IPY_MODEL_91d90b3589d34504b86540503bc5c045"
            ],
            "layout": "IPY_MODEL_af61ae20f0c54fb39031ae8057e2a10d"
          }
        },
        "153c7f4034c34288b17fa5f754778dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20c6a9e746e8424d9108fef18fc625eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41aedc6019454be1841a40740b581568",
            "placeholder": "​",
            "style": "IPY_MODEL_153c7f4034c34288b17fa5f754778dd4",
            "value": "tokenizer.json: 100%"
          }
        },
        "41aedc6019454be1841a40740b581568": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c6d9066f2c420eadf1da741600778a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4edebb16915248d79a96f4bc113c35ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57b07a580bf645fe8aa764ce5d5d56ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "635869f8adeb4198ae80bfff83025c4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75377575d534485da83c4b09d3e4bfa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_635869f8adeb4198ae80bfff83025c4f",
            "max": 50500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49c6d9066f2c420eadf1da741600778a",
            "value": 50500
          }
        },
        "7846707bd8c040e7a3157d61d1ccc737": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7aa3cd9b66834a78a116e07300dbf9b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7e5c786baa4d059a4cb9e734062484": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8c15255b4434e699313d94a6dbf8ad1",
            "placeholder": "​",
            "style": "IPY_MODEL_cc19cf3c6a694706835769d4f4f4cefe",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7df58a727267482e96e8bb3850954637": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81e7a85263e940168bfd349a4ec68954": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89495cabcbfb4086b2fd27c2b4610a25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d90b3589d34504b86540503bc5c045": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89495cabcbfb4086b2fd27c2b4610a25",
            "placeholder": "​",
            "style": "IPY_MODEL_a3013b2ba71040958575ccab47c683c7",
            "value": " 301/301 [00:00&lt;00:00, 40.8kB/s]"
          }
        },
        "99f81bf8fe254674aa78a32d2f574fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a054f4348c27427796fec99e5932b9de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9fe4c230bfb47098c1de7ef2d7621e9",
            "placeholder": "​",
            "style": "IPY_MODEL_a299f18b2a0c44d1b6d9193c2b4c8ca3",
            "value": " 50.5k/50.5k [00:00&lt;00:00, 4.83MB/s]"
          }
        },
        "a299f18b2a0c44d1b6d9193c2b4c8ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3013b2ba71040958575ccab47c683c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8c15255b4434e699313d94a6dbf8ad1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acdf75b484ff4cada055b220a6038e65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af61ae20f0c54fb39031ae8057e2a10d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb6915eb4c64b1bbe7e5168420ea748": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aa3cd9b66834a78a116e07300dbf9b8",
            "placeholder": "​",
            "style": "IPY_MODEL_99f81bf8fe254674aa78a32d2f574fd9",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c9fe4c230bfb47098c1de7ef2d7621e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc19cf3c6a694706835769d4f4f4cefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc540a2aa217407badcece6177f9ff8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d35fb24ff3934fa29d69954dd3ab0045": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d596b46fb7084cafbe19ca93cdfa7533": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d35fb24ff3934fa29d69954dd3ab0045",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4edebb16915248d79a96f4bc113c35ec",
            "value": 9085657
          }
        },
        "db58dc77bafb48229929c12720ea717f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d7e5c786baa4d059a4cb9e734062484",
              "IPY_MODEL_75377575d534485da83c4b09d3e4bfa5",
              "IPY_MODEL_a054f4348c27427796fec99e5932b9de"
            ],
            "layout": "IPY_MODEL_81e7a85263e940168bfd349a4ec68954"
          }
        },
        "e3f20ae03fec4cd5b23f54efd25cd448": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc540a2aa217407badcece6177f9ff8b",
            "max": 301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7846707bd8c040e7a3157d61d1ccc737",
            "value": 301
          }
        },
        "e73ca9dad0b74d828ec7c3c0100be722": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57b07a580bf645fe8aa764ce5d5d56ee",
            "placeholder": "​",
            "style": "IPY_MODEL_7df58a727267482e96e8bb3850954637",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 45.9MB/s]"
          }
        },
        "fe7a7370d8e04ba6984aed9fc96ed650": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20c6a9e746e8424d9108fef18fc625eb",
              "IPY_MODEL_d596b46fb7084cafbe19ca93cdfa7533",
              "IPY_MODEL_e73ca9dad0b74d828ec7c3c0100be722"
            ],
            "layout": "IPY_MODEL_acdf75b484ff4cada055b220a6038e65"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}